{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T10:51:10.830651900Z",
     "start_time": "2024-11-09T10:51:10.820651400Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch, numpy, pickle, random, time, argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Env(object):\n",
    "    def __init__(self, examples, config, padding, jump, maxn, transformer_space=None):\n",
    "        \"\"\"Temporal Knowledge Graph Environment.\n",
    "        examples: quadruples (subject, relation, object, timestamps);\n",
    "        config: config dict;\n",
    "        state_action_space: Pre-processed action space;\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.num_rel = config['num_rel']\n",
    "        self.label2nodes, self.neighbors = self.prepare_data(examples)\n",
    "        self.nebor_relation = self.built_nebor_relation(examples)\n",
    "        # [0, num_rel) -> normal relations; num_rel -> stay in place，(num_rel, num_rel * 2] reversed relations.\n",
    "        self.NO_OP = self.num_rel  # Stay in place; No Operation\n",
    "        self.ePAD = config['num_ent']  # Padding entity\n",
    "        self.rPAD = config['num_rel'] * 2  # Padding relation.\n",
    "        self.tPAD = 0  # Padding time\n",
    "        self.confPAD = 1  # Padding time\n",
    "        self.padding = padding\n",
    "        self.jump = jump\n",
    "        self.maxn = maxn\n",
    "        # self.state_action_space = state_action_space  # Pre-processed action space\n",
    "        self.transformer_space = transformer_space\n",
    "        if transformer_space:\n",
    "            self.transformer_space_key = self.transformer_space.keys()\n",
    "\n",
    "    def prepare_data(self, examples):\n",
    "        label2nodes = defaultdict(set)\n",
    "        neighbors = defaultdict(dict)\n",
    "        examples.sort(key=lambda x: x[3], reverse=True)  # Reverse chronological order\n",
    "        for example in tqdm(examples, desc=\"开始built_graph\"):\n",
    "            src = example[0]\n",
    "            rel = example[1]\n",
    "            dst = example[2]\n",
    "            time = example[3]\n",
    "            conf = example[4]\n",
    "\n",
    "            src_node = (src, time)\n",
    "            dst_node = (dst, time)\n",
    "            src_node_conf = (src, time, conf)\n",
    "            dst_node_conf = (dst, time, conf)\n",
    "\n",
    "            label2nodes[src].add(src_node)\n",
    "            label2nodes[dst].add(dst_node)\n",
    "\n",
    "            # 为transformer做准备\n",
    "            try:\n",
    "                neighbors[src_node][rel].add(dst_node_conf)\n",
    "            except KeyError:\n",
    "                neighbors[src_node][rel] = set([dst_node_conf])\n",
    "            try:\n",
    "                neighbors[dst_node][rel + self.num_rel].add(src_node_conf)\n",
    "            except KeyError:\n",
    "                neighbors[dst_node][rel + self.num_rel] = set([src_node_conf])\n",
    "\n",
    "        \"\"\"需要对neighbors里面的tail根据conf值进行排序，由大到小排序\"\"\"\n",
    "        for h, t in neighbors:\n",
    "            # neighbors[(h, t)] = {r: list(ts) for r, ts in neighbors[(h, t)].items()}  # 生成邻居信息\n",
    "\n",
    "            for r, ts_tuples in neighbors[(h, t)].items():\n",
    "                # 将元组列表转换为列表的列表（每个内部列表包含一个元组转换成的列表）\n",
    "                ts_lists = [t for t in ts_tuples]\n",
    "\n",
    "                # 根据每个内部列表的第三个值（索引为2）进行排序（由大到小）\n",
    "                sorted_ts_lists = sorted(ts_lists, key=lambda x: x[-1], reverse=True)\n",
    "\n",
    "                # 更新 neighbors[(h, t)] 中的值\n",
    "                neighbors[(h, t)][r] = sorted_ts_lists\n",
    "            # print(neighbors[(h, t)])\n",
    "\n",
    "        return label2nodes, neighbors\n",
    "\n",
    "    def built_nebor_relation(self, examples):\n",
    "        \"\"\"The graph node is represented as (entity, time), and the edges are directed and labeled relation.\n",
    "        return:\n",
    "            graph: nx.MultiDiGraph;\n",
    "            label2nodes: a dict [keys -> entities, value-> nodes in the graph (entity, time)]\n",
    "        \"\"\"\n",
    "        nebor_relation = torch.ones(self.config['num_ent'], 2 * self.num_rel + 1)\n",
    "        for head, relation, tail, timestamp, conf in tqdm(examples, desc='正在生成nebor_relation'):\n",
    "            nebor_relation[head][relation] += 1\n",
    "            nebor_relation[head][relation + self.num_rel] += 1\n",
    "\n",
    "        first_elemnt = {key[0]: key for key in self.neighbors.keys()}\n",
    "        for e in range(self.config['num_ent']):  # 由于此处使用的是所有的数据，不存在找不到的情况\n",
    "            if e not in first_elemnt.keys():  # 不在train训练集中\n",
    "                nebor_relation[e][2 * self.num_rel] += 1\n",
    "        nebor_relation = torch.log(nebor_relation)\n",
    "        nebor_relation /= nebor_relation.sum(1).unsqueeze(1)\n",
    "\n",
    "        return nebor_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "开始built_graph: 100%|██████████| 108462/108462 [00:00<00:00, 231747.00it/s]\n",
      "正在生成nebor_relation: 100%|██████████| 108462/108462 [00:01<00:00, 68928.54it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataset.baseDataset import baseDataset,baseDataset_new\n",
    "data_dir = \"data/ICEWS14\"\n",
    "trainF = os.path.join(data_dir, 'train.txt')\n",
    "testF = os.path.join(data_dir, 'test.txt')\n",
    "statF = os.path.join(data_dir, 'stat.txt')\n",
    "validF = os.path.join(data_dir, 'valid.txt')\n",
    "if not os.path.exists(validF):\n",
    "    validF = None\n",
    "dataset = baseDataset(trainF, testF, statF, validF)\n",
    "\n",
    "train_new_F = os.path.join(data_dir, 'train_new.txt')\n",
    "test_new_F = os.path.join(data_dir, 'test_new.txt')\n",
    "valid_new_F = os.path.join(data_dir, 'valid_new.txt')\n",
    "dataset_new = baseDataset_new(train_new_F, test_new_F, valid_new_F)\n",
    "\n",
    "config = {\n",
    "        'num_rel': dataset.num_r,\n",
    "        'num_ent': dataset.num_e,\n",
    "    }\n",
    "env = Env(dataset_new.allQuadruples, config, 10, 10, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T10:51:15.893189200Z",
     "start_time": "2024-11-09T10:51:13.150844400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 7\n",
      "18 15\n",
      "9 2\n",
      "96 7\n",
      "753 3\n",
      "11 2\n",
      "792 1\n",
      "8 2\n",
      "14 2\n",
      "15 7\n",
      "169 1\n",
      "639 1\n",
      "239 1\n",
      "322 2\n",
      "329 4\n",
      "180 1\n",
      "29 2\n",
      "2523 2\n",
      "23 1\n",
      "22 1\n",
      "36 4\n",
      "1012 1\n",
      "42 2\n",
      "109 2\n",
      "46 13\n",
      "95 11\n",
      "84 3\n",
      "882 1\n",
      "49 2\n",
      "188 2\n",
      "50 2\n",
      "440 2\n",
      "52 3\n",
      "55 1\n",
      "60 2\n",
      "3 1\n",
      "1139 1\n",
      "4316 1\n",
      "91 4\n",
      "122 2\n",
      "2458 2\n",
      "93 1\n",
      "185 2\n",
      "1920 2\n",
      "115 1\n",
      "487 2\n",
      "117 2\n",
      "387 2\n",
      "118 3\n",
      "2292 1\n",
      "929 1\n",
      "127 2\n",
      "128 13\n",
      "143 7\n",
      "535 1\n",
      "251 1\n",
      "3963 1\n",
      "5299 3\n",
      "132 1\n",
      "151 2\n",
      "165 1\n",
      "657 3\n",
      "167 1\n",
      "170 1\n",
      "171 3\n",
      "4636 2\n",
      "174 1\n",
      "67 1\n",
      "177 2\n",
      "467 2\n",
      "179 1\n",
      "190 2\n",
      "3622 2\n",
      "195 2\n",
      "1126 1\n",
      "204 4\n",
      "470 1\n",
      "250 1\n",
      "262 1\n",
      "263 1\n",
      "290 1\n",
      "267 1\n",
      "302 5\n",
      "405 2\n",
      "457 2\n",
      "304 1\n",
      "4554 1\n",
      "12 1\n",
      "331 2\n",
      "1760 1\n",
      "348 1\n",
      "393 4\n",
      "509 4\n",
      "542 3\n",
      "408 1\n",
      "389 1\n",
      "471 1\n",
      "4783 1\n",
      "472 1\n",
      "59 1\n",
      "586 1\n",
      "69 1\n",
      "590 1\n",
      "591 5\n",
      "804 1\n",
      "2500 1\n",
      "634 1\n",
      "644 2\n",
      "863 2\n",
      "247 1\n",
      "1589 1\n",
      "668 2\n",
      "318 1\n",
      "675 1\n",
      "678 1\n",
      "680 1\n",
      "730 1\n",
      "1765 1\n",
      "772 1\n",
      "3752 1\n",
      "791 1\n",
      "57 1\n",
      "830 1\n",
      "831 1\n",
      "845 1\n",
      "5489 1\n",
      "847 2\n",
      "1438 2\n",
      "897 1\n",
      "1079 1\n",
      "910 1\n",
      "2405 1\n",
      "936 1\n",
      "10 1\n",
      "1001 1\n",
      "1028 1\n",
      "1029 1\n",
      "1053 1\n",
      "1076 1\n",
      "7126 1\n",
      "1161 2\n",
      "2457 2\n",
      "1295 1\n",
      "1376 1\n",
      "1382 1\n",
      "1383 1\n",
      "1584 1\n",
      "1708 1\n",
      "1780 1\n",
      "1791 1\n",
      "1128 1\n",
      "1966 1\n",
      "2004 1\n",
      "3588 1\n",
      "2077 1\n",
      "917 1\n",
      "2081 1\n",
      "1094 1\n",
      "2099 1\n",
      "2111 1\n",
      "2346 1\n",
      "1510 1\n",
      "2355 1\n",
      "760 1\n",
      "2370 2\n",
      "154 1\n",
      "106 1\n",
      "2817 1\n",
      "2902 1\n",
      "3182 1\n",
      "3346 1\n",
      "3516 1\n",
      "465 1\n",
      "4105 1\n",
      "4573 3\n",
      "4679 1\n",
      "2329 1\n",
      "5136 1\n",
      "900 1\n",
      "5411 1\n",
      "2607 1\n",
      "5453 1\n",
      "2165 1\n",
      "5564 1\n",
      "2044 1\n",
      "5726 1\n",
      "5737 1\n",
      "6800 1\n",
      "381 1\n",
      "6930 1\n",
      "2720 1\n",
      "7051 1\n",
      "7075 1\n",
      "1805 1\n",
      "7125 1\n",
      "33 1\n",
      "7127 1\n",
      "63 1\n"
     ]
    }
   ],
   "source": [
    "count = defaultdict(dict)\n",
    "for k,v in env.neighbors.items():\n",
    "    entity,time = k\n",
    "    temp = 0\n",
    "    for k1,v1 in v.items():\n",
    "        temp += len(v1)\n",
    "    count[time][entity] = temp\n",
    "    # print(entity)\n",
    "    # print(v)\n",
    "    # print(count)\n",
    "all = 0\n",
    "for k2,v2 in count[8736].items():\n",
    "    all = 0\n",
    "    print(k2,v2)\n",
    "\n",
    "# print(count[8736])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T11:06:19.623893600Z",
     "start_time": "2024-11-09T11:06:19.568894600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
